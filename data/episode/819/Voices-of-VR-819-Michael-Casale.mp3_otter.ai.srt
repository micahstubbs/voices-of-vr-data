1
00:00:05,370 --> 00:00:07,680
Unknown: The voices of VR podcast

2
00:00:11,820 --> 00:02:53,790
Hello, my name is Ken by and welcome to the practice of VR podcast. So this is the final episode of my series of looking at the future of neuroscience and VR. I'm going to be talking today to Dr. Michael Casali. He's the Chief Science Officer at striver. So Strieber has been on the bleeding edge of looking at how to train everything from Elite quarterbacks in the NFL, to Walmart managers, and lots of really big companies are starting to use VR training. So Michael started off, he's looking at computational cognitive neuroscience. He's a behavioral scientist looking at behavior and learning and doing it in an academic environment where he felt like very constrained to use these abstract constructs and to do these different tests on dozen people. And it just wasn't necessarily convincing to him that this was going to translate into the real world. So when VR came along, it was like a dream come true to be able to actually start to simulate these real world environments, put people into these different situations and actually see if these learning theories actually applied. So strivers working with some of the best football teams in the world, from college, Clemson Tigers to like lots of different people within NFL, lots of quarterbacks who've been doing these trainings within VR. And then also working with huge companies like Walmart, who made a big announcement number of years ago that they had bought like 17,000. Oculus goes, that was a huge turning point, I think in signal not only to the wider VR industry, but also dockless, but itself to get their own enterprise offerings in order and to actually kick up and start up a proper enterprise department there at Oculus, because, you know, this is a huge market that's out there. And so I had a chance to catch up with Michael Casal. And I always love talking to him, because he's really on the bleeding edge of showing the future of what's possible with the training, working at a scale that there's not a lot of other people in the industry that are working with as many people as they are their drivers. So I think they're at a point where they're able to take a lot of the lessons that are being proved out. And both the research and academia, Jeremy valence and Stanford's of one of the advisors involved in the company as well. And so he's also been on the bleeding edge of all this research and trying to integrate this and take it to scale. So they're being able to take these latest technologies and start to deploy them out. And so just kind of have a state of the union in terms of where we are trainings at what they know and what they are kind of learning about the nature of the mind and the nature of learning as well. So that's the programming on today's episode always is a VR podcast. So this interview with Michael have been on Wednesday, June 19 2019, at the Games for Change Conference in New York City, New York. So with that, let's go ahead and dive right in.

3
00:02:54,210 --> 00:03:21,630
So Micah, Sally, I'm the Chief Science Officer at striver we're generally using immersive to technologies to train and the workplace. So this can be anything from folks in the front lines in the sales, retail sales industry, or even in managerial positions, to be able to communicate better with co workers, etc. So if you can imagine anything that happens in the workplace, that's training related, that's something that we believe we can make an impact and and improve.

4
00:03:22,470 --> 00:03:36,960
Right. And so this is, I think, our third conversation we've had on the record. And we've talked before about a variety of different issues. But I'm just wondering if you could catch me up in terms of your background, and a little bit more context there, but also your journey into immersive technologies. Sure,

5
00:03:36,990 --> 00:07:44,910
yeah. So by training, I am a computational cognitive neuroscientist, which is a mouthful, so did a PhD in that domain and the psychology department at UC Santa Barbara for a while. And during that time, I really focused my research on a lot of just basic cognitive phenomena, learning and memory, how people acquire information, how they make decisions with that information. And specifically thinking about the brain areas that observe that and we really were after is building these models of, you know, obviously, not completely accurate models, but models of the brain so that we can better understand how that happens, that decision making that categorization that memory, that learning. And so that was really fun, I had a great time with it. But I was much more interested in applying that research outside of the domain of academia to see if anybody can find it useful. So and then during my PhD, I actually met a guy who was working in a lab right across the hall from me, Jeremy Beilenson, who's now a professor at Stanford runs the virtual human interaction lab. So he and I became friends then. And so I took a passing interest in the work just because VR was pretty nascent, it was cool just to, you know, get an experience that was unlike any other. But the technology was obviously a lot more infantile than it is now. But we always kept in touch even after you went to Stanford, and then I had been working in the actual medical research space of all places, doing behavioral research from new technologies could help improve various mental health behaviors, patient behaviors, etc. and he basically calls me up one day, about four years ago and says, Hey, I have a master's thesis student, it's really interested in training football players with VR. And he's like, I don't know anything about learning. I don't know much about sports. But you know, about both, and I know about the VR. So maybe we can tag team this. So we both co advise on his master's thesis. That gentleman was Derek Bell, he became our co driver. And so Derek did his master's thesis, everything was good, pretty interesting stuff. But then like a lot of academic projects, it just kind of stopped, right. And that was my issue with a lot of academic research. It was like, well, where does this actually have a place in culture and society. So you founded a company shortly thereafter, and asked if I want to be a part of it. And at that point, it was just so uncertain and unknown, especially the VR space in general, that I was I said, you know, I'd help consult anything you wanted on that front. But I was very dubious about the fact that this can be a real value proposition for the world, especially a little we knew. But a lot, the NFL teams that we worked with, took it on its face that this is going to help, I just saw the power right away of being able to transport someone onto the field, and get that real world learning scenario. But they couldn't get sitting in front of a video, listening to coach talk. So again, you know, for that year was kind of interesting, I help how much I could and then not too long, after the company started, Walmart of all companies came along and said, Hey, that sounds a lot like what we want to do skill wise, and I started thinking about, it's like, well, one's a football player, one's a Walmart employee. But from my perspective, from the kind of learning perspective, there's a lot of similarities in terms of, you know, what you're doing skill wise, what you're learning and what you're having to kind of apply that decision making in the real world. So I got really excited everybody to come to get really excited. And we started to pursue this enterprise route. And that's when I came over full time was driver and became the chief science officer. So now I, because of my competition, and background, and because of my learning background, I have basically set the methodology and the foundation for how we develop immersive training. So basically, you know, we want a good experience, we want engaging experience, but we want one that's true to the learning science. And so developing it with those best practices in mind. And then on the other end of that, the analytics, right, the insights that we can get from these learners is unprecedented. And it's going to allow us to be able to really understand what's working and what's not in the space of VR. And then kind of like I said, Get in the mind of the learner, are they prepared really, right? Because even if they sat in front of a training in front of a computer and took a couple of multiple choice questions, doesn't mean they're actually ready, we can actually follow their behaviors in a much more rich and relevant way to really understand how prepared they are. So it's been exciting. We're working now with dozens of major companies, 10s of thousands of employees, and you know, getting a really good understanding, unprecedented understanding of how VR is able to actually shape behavior. So couldn't be more excited for the work that we do.

6
00:07:45,630 --> 00:08:43,350
Yeah, I remember talking to you about training elite quarterbacks and some of the skills they have to do in able to like, look at a scene and be able to categorize it. And I've thought about our conversations a lot as I've been playing beat saber a lot, because beats Uber's, very simple in the sense of like, you have all these blocks are coming at you, and you have to be able to discern the pattern. And your body unconsciously learns that process, like you just have to keep doing it and that eventually, you're able to see it, it's been so surreal for anybody who's just getting started with beats a very encouraging them to jump into expert plus and to see how impossible it feels. But then to go through the game design mechanics and then slowly kind of build up to that point where you can actually perceive what's happening. So I've thought about that in terms of like, wow, that's very similar to what quarterbacks have to do in terms of like, having the defense be able to identify the patterns, and then to listen to the intuition and then actually taking the actions. So the thing that I don't understand is how is being an elite quarterback like being a Walmart employee through the lens of a computational neuroscientist?

7
00:08:43,470 --> 00:12:12,840
Yeah, that's a great question. You just have to trust me. No, I'm kidding. So I think the high level answer to that is, and I'll talk maybe a little bit more detail, the high level answer is the learning systems that we know govern. A lot of our day to day decision making are really kind of unconscious learning. So the thing that I studied, in particular, doing my academic work was dissociating different types of learning systems and how we categorize information visually in the world. And there's a lot of instances when we are able to use like these really simple heuristics that you memorize, right. So think about your stop that a light and it turns from red to green, then you know how to go right. And same thing here. Same thing in Australia, many countries around the world, it may look different, that stoplight, but you're looking for basically just one of the dimensions, which is color, red or green. So you can take that rule, memorize it, apply it anywhere. But I think that's a lot less common than a lot of the other types of learning that we do. So if you think about just what I mentioned, navigating a store, right. So if you're a manager at Walmart, you have many dozens of probably not hundreds of decisions you're making in an hour about people about products about the safety of the store. So there's a lot of things that you have to kind of keep in mind. And it's impossible to be able to do that in a conscious way that you're kind of systematically running through all these things, what you're really doing is you're taking in all the sensory information, a lot of visual information, but also a lot of auditory information. What are people saying to you? What do you hear in the store, do things look out of place, maybe smells are part of that, too. And you're basically combining all of this information at an unconscious level. And we know this to be true is a lot of what I studied, and you're able to make decisions, and you only know how to do that through repeated exposure through a lot of trial and error. And if you're a manager at Walmart, you don't really get that, right, you get like a training that gives you the rules to follow, but not how to apply those rules and not really how to learn them. So it's kind of like a primer, but you still have to go through that experience. And sometimes you're just not prepared when you're floor. Okay, so now take a quarterback, the parallel there is, again, you're taking in a lot of sensory information, right? Even on every single play, you're looking at positions of players, you're looking at the situation, the context, so if it's, you know, if anybody's familiar football, you know, whether you're close to your goal line, or close to the other teams go line, what down it is the distance, the weather, how your players are playing, like all these things, and you're not going to sit there in a matter of 20 seconds and go down the list. And kind of individually consider them they kind of form this kind of agglomerated per set, right. And so this is something that we know to be true, again, from a lot of the work that I studied in this kind of unconscious learning this implicit learning system. And so again, the rules that govern learning in both those situations are the same. We know that, for example, real time immediate feedback. And realistic feedback is really critical for learning. If you don't give that and learning situations, it's unlikely that people are going to be able to learn so in other words, have them make a decision and tell them if they're right or wrong, as opposed to, hey, look at all these instances, this is what you should be doing kind of follow this model that doesn't necessarily work for that kind of learning. So it's really that exposure, where you're able to combine all those real world perception that's really critical. So, you know, the common place training for both those situations is a very observational rule based one. And that's not nothing like it definitely helps learning to some extent, but it's not sufficient, right, it's not able to get you to that place where you're able to make those decisions, you know, most of the time accurately in the real world. So that's the parallel that we draw between a lot of types of learning that we do, but certainly a Walmart manager and a quarterback, and how similar they actually are in the skills that they have.

8
00:12:13,950 --> 00:13:01,170
So it's having these debates with some of my friends about this dialectic between the internal external and the collective and the individual. So the objective individual thing would be a fact an objective fact that you can observe and prove and falsify in some way, and then the aggregation of that. So the collective of that objective is knowledge. Well, this is sort of up for debate, I'd say. But that's how we kind of think about it, like all these aggregations of facts, lead to knowledge, but then there's intuitions that are non falsifiable, just like a feeling. And then those maybe aggregate into beliefs. But I don't know if the brain actually makes the differentiation between facts and knowledge and beliefs and intuition, if it's all just kind of mashed together. And so I'm just curious, like, how is this information being stored and referred to in our brain?

9
00:13:01,410 --> 00:15:30,960
That's a great question. I'm not actually sure if anybody knows the answer that but I'll take a stab at it. So the supposition is that you have intuitive beliefs that are kind of maybe inherent or that you formed unconsciously. And then on the other side of that, you're going to have explicit facts that we know we've discovered throughout the world. And that, you know, is there basically different brain mechanisms for storing on information? And then how we come to have knowledge versus beliefs? That's a great question. I this is probably something has spent some time studying this, my guess is that yes, I would say in the differences, probably not necessarily in Well, probably in the representation of the information in the sense that those beliefs that are intuitive are probably going to be much more indelible. Like in other words, we probably have them represented as much more kind of hardcore, like the I think you were alluding to this like kind of wired beliefs that are hard to change. And so and then a lot of this is probably, you know, evolutionary, right, the way we kind of perceive the world, the stories that we tell ourselves, these narratives that we live with every day. And I just to get really philosophical with this, I think it's a great probably example of an intuition that's really indelible, that we don't really are ever taught. But it's this mechanism that we use where, you know, we wake up every day, and we have this narrative, we don't really consciously access it. But it's the narrative that lets us kind of determine what we're going to do that day. We don't wake up every day. And we say, like, Oh, shit, something completely new, right? Like, it's everything's on the table. No, like, this is who I am, I wake up, and I'm just who I am in this job, right? These are things that you don't actually, like, consciously tell yourself, right, but you live by these principles. And I think maybe that's what you're referring to is kind of these intuitive things that there's no knowledge that's been collected or facts that's been collected that says, you know, can't is this person in here, the things about knowing everybody that would talk about, you might have some of the things to say about you, but we represent you differently, right. And but you represent yourself in a certain way. And that's really what you live by, you don't live by some kind of like body, collective body of knowledge, you live by your intuition that you've kind of developed over the years about who you are in the world. And that intuition, I think, is really hard to, I guess it's really, it's really hard to alter that. And it's necessary, right? I think from an evolutionary perspective, we often kind of tie together these facts and narrative. So maybe it's more of like that. It's like more of a meta knowledge. But like, I think that the way we string together information, when the story that we formed from that, whether that's true or not, and objective or not, it's the thing that we live by. And I think that's a really kind of indelible construct that everybody has. And I would not say that that's based on objective, systematic collection of knowledge that's just based on something that your brain is constantly doing. But that's a really like powerful thing that drives your behavior. Does that make sense?

10
00:15:31,260 --> 00:15:37,550
Yeah, what comes to mind is the predictive coding theory of neuroscience. I'm not a familiar with that in terms of neuroscience theory.

11
00:15:38,160 --> 00:16:39,900
So the way I know predictive coding is you see something and you kind of anticipate maybe one case, it's like, you're assigning value to a particular object, and then you're seeing so when we think about it from like, the learning perspective, a lot of that is based on the neuroscience of the reward structures involves you see an object that elicits a certain representation in your brain rain, and if you're using it, so I take a test and you say, Okay, this thing belongs in Green Bay, this, I think, belongs in Group B. And you say, Okay, I'm pretty sure it belongs in Group A, and these neurons are predicting that behavior, well, if you're wrong, that's a really big signal that your brain pays attention to cause some energetic release, and then your structures are altered accordingly. And then likewise, if you're making correct decisions, and you're getting them, right, it's expected, right? Your neurons are predicting that this is going to be rewarding, because you were right, and actually that Dominus is much smaller. So it's really the errors that are causing a lot of the alterations in the neural structure. So that's how I've come to know predictive coding. I don't know if that

12
00:16:39,930 --> 00:18:46,710
Yeah, yeah, it's I was at the Canadian suit for advanced research, they had a workshop and they had a neuroscientist talking about the predictive coding theory of the the mind also did an interview with a creator who's got this experience called me you. But when my understanding was that when we're perceiving the world, we're not just like perceiving it as it is, we're actually fusing together with all of our prior experiences of that world and of the context. And we're kind of doing this comparison between our models of the mind with what we're experiencing, and then there's this error code that then if it does have that error, then there's sort of a change and plasticity. And so with me, you they were doing like this, moving your body around, but then kind of slightly changing it in different ways. So then you were kind of like, having your body representations be messed with to a certain degree, but it was giving you this sense of novelty, because it's not something you expect. And so you have this play. And I feel like in some ways, the way that we experience the world is that we want that novelty, we want something to kind of blow our mind in some ways. And so we do chase after things that are new things that are different. And that because it does give us that double main hit. But I guess the thing that I was thinking about with that predictive coding theory is like, well, these representations, I think of something like artificial intelligence, where there's traditional coding that is very symbolic, and you can have a human read it and write it and it's linear, you see the code. And then there's the nonlinear parallel, a neural network architecture, which gets provided an experience of data, and then it gets all these weights in a more relativistic way. And then you have this Gestalt that it's able to make an inference, but it's only able to do that after all this data, but its sub symbolic, we can't point to any one neuron say, Oh, this is why this neural network said that this is a cat, not a dog, it's like very difficult to kind of pin it down reductive Lee, and so that's the question I have is in terms of like this, unconscious versus conscious, I don't know if it mirrors the way that we see artificial intelligence as this symbolic and sub symbolic. If there are certain things that we can pin down and have like, a little bit of an audit trail and the black box versus whether or not, there is no audit trail and our beliefs and our opinions, or if it's all just kind of mashed together, and there's no audit trail at all.

13
00:18:47,090 --> 00:22:08,970
Yeah, there's a lot of thoughts there. So you're kind of more macro point about artificial intelligence, and really understanding the parallels between that and human intelligence. Pretty interesting. So I obviously follows space pretty closely, even kind of working and dabbling more or less as a researcher back in the day and kind of helping build these artificial brain networks to help make decisions. There's a really fundamental problem in neuroscience, which isn't prohibitive for us to kind of keep learning things that are important and useful about, you know, the brain structures that underlie behavior. But at some point, you run into issues and I think this is one of them in artificial intelligence, which is, how do you represent something abstract and immaterial, like a thought, or an emotion or a memory, and something that's so material, which is basically electricity, right in the brain, chemical and electrical firing in the neurons So that to me, then I think every neuroscientist will probably acknowledges until you really solve that problem in terms of words, that direct causal mechanism. So I'll give a counter example of that, which is, with other parts of our physiology, heartbeats, for example, right, you can actually follow very particularly in a very physical way, the bioeconomy interactions that happen, you know, in the nervous system that would cause a heart to beat, which is a very physical manifestation of all of that other biochemistry, right, so you have a bunch of cellular interactions, chemicals are being swapped, electricity is being propagated down a bunch of kind of chain of cells, that result in a physical compression of a heart. And that heartbeat is critical, obviously, for our lives. So you can follow the audit trail. And that's the problem with the eyes because you can't see we're not touching any they can't see it, it's really hard to measure a thought and a memory and an emotion. So even building any kind of machinery that would hopefully replicate that even if you and I think this is your point, even if you could sufficiently represent that in an artificial network, you could say, I know exactly how to create an AI that thinks like a human. Your point is exactly right. Well, where's the audit trail? How do we actually go into the brain, that artificial brain and start to mess around with it in a meaningful way make predictions about why know if I mess around with this area of the brain and the cells I'm going to get? We don't know that. And that's an even more fundamentally, we're not even close to that and AI. But even if you could build a network now, and you can kind of more or less like predict people's movie preferences, you don't necessarily know like, why you don't know the alterations to the brain, or even an artificial network that would allow you to understand that network and how people come to make the decision, what parcel think to make it concrete, like in that movie, prediction, representation, and a model, you can have features like all the past movies that you've watched, maybe waiting, the more recent ones, looking at your musical taste, looking at your social, let's say, say you had all access all this information that became features and the network. To your point, even if you predicted with really good accuracy, 900% accuracy, movie predictions, you don't know what features are being accounted for more relevantly, we can't even do that in a simple context. And let alone do that, kind of in that fake brain context I described as well. So that is a very hard problem. But I also think that's never going to go away, unless you solve the more fundamental problem of how you go from something. So material like these biological cellular interactions to something so immaterial, like a thought, does that make sense?

14
00:22:09,180 --> 00:23:39,540
Well, yeah, it makes sense that we don't know what consciousness is we don't have it's like the hard problem of consciousness to some degree, which is that the neurological correlates to be able to jump from the the aggregation of all these weights into like, those level of the abstraction, that is the Gestalt. And you know, when I go and cover artificial intelligence at the International joint conference for a number of years ago, I was talking to a researcher, who said that they were actually combining like, looking at Wikipedia pages for bird descriptions, like, this is what this bird looks like. So a human can read that, okay, this is what this bird looks like. And they can go out and see a bird is like, okay, that's that bird that from a perspective is Joe start learning, you have had one instance of that bird, and you can identify it based upon the features. That's something that AI can do right now to be able to blend this symbolic representation. And then you get the translation of what that means in terms of their perceptual input that you're getting. And humans can do that. But at this point, we haven't figured out what the interface between those ideal forms of those archetypal representations, those categories, schemas that we know and we can name, so all of the advances in AI in terms of AlphaGo and the alpha zero, that it's combining this sort of top down hierarchical knowledge base with the sub symbolic neural network architecture. So you have the top down and the bottom up working together. So a lot of like, there's ways to start to do that. But I guess from a computational neuroscience perspective, it's like we're trying to advance the AI and maybe we'll be able to replicate it. But it's still a bit of an open question of how to interface between those high level abstractions with the low level perceptual input.

15
00:23:39,690 --> 00:25:24,840
Yeah. So I think one key thing here, and I obviously like guys, like Steven Pinker talks about this a lot, which is, so in a kind of AI model sense into user example, if you just give it one instance, of a, of an object of a bird, that's wildly insufficient for to go out and have successful classification. Part of the reason I would argue, and I think other people would argue, is because we're not we're not starting from zero, the model starting from zero, but we're starting with these kind of like pretty robust structures, right? We're not blank slates. And it's really critical to understand those templates that we're born with. And you know, they're going to look a little bit different from human to human. But there are some very fundamental things across the species that we probably have as templates for the world in a way to scaffold on top of right so that we can integrate information easily, robustly so that we don't need to see 10,000 instances, we can extrapolate the key information right away, we wouldn't be able to do that if we had none of that structure, or none of that kind of those templates that existed. So but that's basically what you're doing. When you're starting with these AI structures, if you don't give it what you're saying its top down types of schemas to work with, that has nothing to integrate into. So of course, it's going to take a lot of exposure. So I think that's one fundamental difference. And I don't know if that's necessarily going to solve that problem sufficiently. But I would imagine, it would help a lot if somehow you can understand the base representation and the base kind of ways that we have to learn as humans and and being able to kind of build that into AI. But because we don't know, people don't want to make any assumptions with their model, they want to kind of leave it relatively unbiased, which is probably smart. Because if you start to bias in the wrong way, because of the uncertainty, you could actually have worse learning, right, and takes longer for that network to eventually learn. But I think that would move the field forward understanding, like I said, the kind of human based representation, how we integrate knowledge, etc.

16
00:25:25,980 --> 00:26:15,930
Well, what I think is very interesting is that for one, I think VR is this interdisciplinary melting pot that is bringing together all these different disciplines. And I think there's this interesting blend of neuroscientists, I think more and more are starting to look at VR, at the Canadian Institute for Advanced Research brought together a number of different neuroscience researchers who are starting to use VR to do very specific research that couldn't be possible with the level of tracking that they're able to do. And I tracking the EG, that's like a whole new world of learning about the brain with virtual reality. And then on the other hand, coming from the more industry side, what Strieber is doing with the scale that you're operating at, you're actually able to have sets of data that is unprecedented in terms of understanding about the nature of brain and lunch of learning. And so what are you learning about what the nature of learning and the nature of memory is?

17
00:26:16,110 --> 00:29:56,940
Yeah, so yeah, I think what you said, You nailed it near you're obviously smart guy. And you can kind of see the the future here, and I think that is an opportunity that Strieber has, it's pretty unprecedented right now, you mentioned the ability to capture data in a way, that's not just the volume of data, but the way that we capture. So just to take a step back, one thing I left out of my preamble was, you know, when I was actually doing my dissertation study, one of the things that was, you know, somewhat satisfying, but somewhat frustrating was this idea that we were working in a lab, we were working with very abstract representations of objects of learning, because we had to if you really want to kind of do it cleanly, but then you don't really know if what you have found about found out about human behavior and your studies actually applies in this kind of real world environment, because it is multi dimension, it's not as clean as an experiment in the lab. That's what VR offers. And so I sat there one night thinking about like, Man, what if I had a real world environment, one that I can control, like, I could control an experiment. And that's exactly what VR is, for us. It's basically a real world environmental experiment, where we can control the variables meaningfully, but give you a realistic sense of what the world is like and understand how you react to it. And all the measurements that come with it. And you mentioned, the great advancements being made, and a lot of the bio physiological measurements, which you know, are really key and can provide a lot of insight. And that's only, you know, advanced. So that's great, that's exciting on its own. And then couple that with the other thing you said, which is the volume of data, right, that's the other thing about laboratory studies, especially in the world of Behavioral Sciences, you have studies that maybe best case scenario on the order of many dozens, but certainly not hundreds, if not thousands, and then we have 10s of thousands. So we're just at the kind of like inception of learning about that we are business, which I'm learning also doesn't always lend itself well, it's a kind of research, right, you have to kind of take opportunities, we're also finding a lot of these companies have become willing integrate partners with us because they want understand they're actually truly interested in wanting to understand better their employees, because they know if they can create a more friendly work environment, one that people can really actually upscale themselves, where you don't have to just kind of rely on the whims of, you know, the working world that we live in now, in a lot of places for upscaling to happen, or promotions, etc, you can actually have people take that into their own hands by offering them meaningful training and meaningful learning experiences. So they're really interested in that. But like I said, we're just kind of at the beginning, one thing we have done, obviously, is to be able to show, you know, minimally, that VR has become a really effective training tool in at least being able to replicate a lot of the on the job training that we see. And then kind of hopefully, be able to further that by offering them even better training than on the job because of all the variety of instances that they can get exposed to etc. But as far as like memory, retention, all that stuff, so we're obviously going to learn about that as well. How much training does it take? How long does it last? What are the individual differences between people? I think, for me, what's really interesting, what are the conditions, right, that people are going to learn optimally. And so we talked a lot about things like flow states, ism, it's really interesting to me, that you can actually potentially have a person who's going to be better at learning and different times of the day, or if you induce them into certain kind of physiological states, they're going to be much more receptive to getting that information and having an information stick. And so I think that's one thing that we're kind of after two is we can see just from the data, who's learning Wow, who's progressing. Wow. And then what are the conditions that are really facilitating under fostering that, both from the content experience but also from like, they're just basic, you know, physiology? That would be a really interesting question to answer. But you know, like I said, deploying at scale has been great. I think we'll be able to uncover these learnings over time. But we're just at the very beginning of kind of just making sure that people have training that they think is useful, and, and is interesting, and it is actually helping them. And I think we're starting to learn all that. The other stuff kind of research stuff over time. So it's a pretty fascinating proposition for me.

18
00:29:58,680 --> 00:30:57,480
I've been to a number of different quantified self meetups and Steve Jonas from Portland was talking about the space repetition programs that he was using to be able to learn information and remember it where he would tell me that in order to learn like vocabulary, you would learn it and then you would sort of do one iteration, and then you would be tested. And you would report back how strong you remembered it. And then based upon that, then the algorithm would tell you when the next time would be when you were going to need to know that information, which is just at the moment that you're about to forget it according to this sort of system. And so you have these spaced repetition, ways of kind of spacing things out. And if you just think of something like beat Saber, you can play beat saber for like eight hours the first time you play it, but you're not going to see much progress in one day. versus if you sort of start to do it each and every day. Because there's this unconscious integration process that I think is happening with things like that. So that's the question is like, you're doing these trainings, do they you find that they have to kind of do a space repetition and kind of space it out?

19
00:30:57,860 --> 00:33:21,990
Yeah, so we definitely advocate for that. It's interesting, you brought that up. So that is what was pretty well established phenomena. Now in the learning cognitive science literature, is this idea that if you space that material, it's typically better learn. So if you have the same amount of total amount of learning time spent, but in one instance, you space it out, and I think the other condition is typically for do is massing, the learning, what's really happening from a neuroscience perspective is your kind of repetition, fatiguing the neurons that are representing that information. So you're not kind of letting it settle. And there's not this refractory period where on the second presentation, if you space it out well enough, you actually have a stronger response naturally to that information. But if you don't space it out sufficiently, you might actually have a weaker response. And so the plasticity is going to not happen, certainly not the same pace, if you mass information versus space. And so we're very sensitive to that. And we often advocate, we build our training accordingly. So we do leave time to space. But definitely thinking about next level things like being able to build intelligent algorithms that can say, adaptive Lee, for each individual, how we should present this information next within the training session, or even kind of map out a training session over time. One of the things that we're running up against right now, of course, with companies is it's a slow start, right? It's always like the change management, they are coming to this VR thing, embracing it, knowing that it can change, but it's kind of one step at a time. So even incorporating VR, the headsets, etc, into the organizations is a big step forward, then making sure that you have enough time to train is a big step forward. So we're getting there with a lot of these companies. But we haven't been able to really take advantage of all these kind of like you mentioned cool learning principles that we know work. But it's slowly but surely, we're starting to be able to make headway with these organizations, especially the more progressive ones, to be able to actually do things in a way that's consistent with best practices. That's exciting to see. But it certainly not happening overnight. But you know, I have a list seven priority list of like, okay, maybe now it's spacing, okay? Now, it's, you know, making sure that they get immediate feedback, now, it's making sure that they get enough variation in the concept, right, so that they're not just learning one repetition of one kind of event, they're actually learning a series over them, that's going to be a more robust way for them to learn and make decisions in the real world. So there's all these learning principles that we know are great, some of which were able to incorporate Now, some of which were, you know, it's kind of a slow and steady one at a time as we start to grow within the organization, and they start to dedicate more and more resources to the training, because we know, you know, they know that it's going to be more effective for their employees at the end of the day.

20
00:33:22,980 --> 00:34:05,700
Well, being here at the games are change, a big topic that comes up in education space is assessment, and being able to like quantify, in some ways, the before and after state of going through and to say that this is effective in some way. And you look at elite quarterbacks where they're playing a game, and then to certain extent they're performing. But you know, how do you tell what's happening with like you said, there's dozens of different factors that are being educated all at the same time that are sub symbolic, and they're unconscious, and you can't even put a number to it. So how are you going to, first of all, establish that, but for Walmart employees, they're on the job, and they have to be able to maybe deal with different situations, but how do you start to try to quantify and assess something that is fundamentally qualitative and unquantifiable?

21
00:34:05,970 --> 00:37:51,480
Yeah, that's a good question. I some of these things I think will always remain, like you said, kind of qualitative, I do think that's the great thing about VR is we are going to be able to start to quantify some of these things. So learning behavior, typically, because of a lot of the current resource constraints that I mentioned, is very coarse. So we think about paper and pencil and multiple choice test is the main avenue, because it's the easiest thing to do. And it's close enough. But it's really not because you know, you send people out in the world who did 90% correct in their test, but they're just wildly unprepared when they get in the real world situations. And they're having to learn on the job anyway. And that takes time. And there's a cost to that. What we can do in VR is we can actually start to look at like more nuanced measures of expertise. So instead of just looking at, Hey, what did they answer and that multiple choice question we can get in us, you know, and again, use the research literature that's out there that have studied experts. And so thinking about sport in particular, there's actually a really, really interesting researcher, I don't know if you've ever encountered I'm Jocelyn forbear. I think he's an ophthalmologist by training. But he works a lot in the Decision Sciences and behavioral sciences. And what he's really interested in with athletes is this idea that you can see their pattern of gaze and where their pattern of gaze goes in the course of sport, to really understand their level of expertise, right. And he's not doing this top down, he's actually bottom up looking at how experts see the world and are able to extract best practices from that. And then you can use that as a way to say like, hey, this person really knows what they're doing, or they don't. And even logically, it makes sense, it's consistent, they're looking at the plate develop in a certain way that a novice doesn't. In other words, they're anticipating where things are going to happen. microsecond, sometimes before they actually happen. So their eyes are places where the novices aren't and they're more efficient with their gaze are looking at fewer more meaningful places. And so we can do the same thing. We can put someone in an environment, a highly multi dimensional environment, whereas you know, you test them individually. Where should this employee go tomorrow? How much inventory Okay, they do really well on that test when you kind of test them individually. But now combine all that information at decision making like you wouldn't the real world, and then see how they perform right? See where their eyes go for see where they decide to choose to explore first and that environment. And that can give you a sense of how expert they really quickly do it. Right timing is a big component to this too. So testing people under kind of cognitive duress and cognitive load is also a good way to test how expert they are, as well. So we're getting better and more nuanced ways to understand, hey, both of you maybe got 90% on this paper and pencil test. But you're really pretty different in terms of how expert you are. So I actually think for the within VR, because of the data that we have, we have it's so much more of a rich data set behaviorally, we can start to make better quantitative assessments of who's really expert who's really ready to go and who's not, ultimately where we'd like to go with this is kind of seeing, you know, hey, do people in the real world? What does that performance look like? And then what does their VR performance look like? Right, then we can actually get to real predictive models and say, we know because you did this in br what's going happened to six months on the floor, if you put you out now versus train you a little bit more. And that's data that we're hoping to capture as well. So that we can put people on the floor and put people you know, in quarterback positions that are actually going to be prepared, instead of putting them in an environment where they're kind of set up to fail, right, they don't have enough training. And I think that's going to be a huge thing for companies going forward is to be able to feel confident and have the employee feel confident that they can do their job. And if they can't, we have access to training that they can't get otherwise, right, this ad hoc system, they can just pop on an Oculus quest, or whatever the headset does your and actually get that training in an efficient way that they currently can't get in the centralized a human led training that they get now that's actually not that effective. So I think predictive modeling, combining the VR data with the real world data and understanding how we can start to see if people are prepared to go on to the job or not, I think that's going to be a really powerful thing going forward. Yeah, and seeing

22
00:37:51,480 --> 00:38:50,280
some of the videos of striver of what was happening with the coaching of the elite football quarterbacks, was that the quarterbacks are going through the repetition. But then I find it was really interesting to see how the quarterback is in VR with a coach there, watching it on a screen and being able to then get real time feedback from a coach and not just sort of automated through the technology, but to have the technology be able to have this real time coaching feedback, which I also thought was kind of a new thing in some ways of being able to like simulate that context and have the coach standing right there and to play it again, to go back to the exact same experience and to see how they do it and give that to you. So that seems to be like a huge innovation in terms of real time feedback. But what are the other aspects of real time feedback that you're trying to do for maybe something that may not have an opportunity to have like a coach there with Walmart? I'm not sure if they have people that are there coaching them in real time, or if it's all sort of automated and self contained, but just generally, where you're going with the real time feedback?

23
00:38:50,310 --> 00:41:55,710
Yeah, so it's a really great point. So one thing I should mention is what you're describing, which is a lot of times, we're never eliminating, one was never eliminating the human, we're just mentoring their capacity to facilitate training. And so what happens now is, you know, if you have a human led training someone gets, it's like a classroom and someone gets up, they talk, you're listening, it sounds abstract, it's hard to see how that actually applies in the real world. So maybe you're getting the information, maybe you're not, it's all text based. So you do want to take space test, but you can't really do in the real world. Well, now what happens is, okay, forget all that, we'll just put you in the environment, see how you do. And as you're making decisions, we can coach you along the way. So that, as I mentioned just a few minutes ago, that real time feedback, we know is critical for this type of learning this highly multi dimensional learning that takes place for most of these learning and decision making situations. So we're now able to get people in the real world environment and have them make decisions as they would in the real world, we can give them feedback right away in a meaningful way, which we know is critical for learning, you know, and right now, like you mentioned, in a lot of our football situations, and even some of our enterprise situations, it is human lead. And we think that's fine. And that's powerful, too. And actually one of the really interesting things that facilitates the discussion between the facilitator, the instructor and the employee, or the quarterback, or the coach that hadn't happened for right now they're engaged in a way now they can understand, oh, well, what was now I needed to actually do that when I saw this guy kind of coming off the line, you know, and they can have a more meaningful conversation about what they didn't know before. It sounds like you don't know what you don't know. So until you in that situation, you realize, you have a weakness, and you want to explore that further. That's creating a conversation with instructors and coaches and employees and quarterbacks that hadn't happened before. But as far as next steps for the technology, I think another really powerful thing is to be able to see the consequences of your feedback, right? Like, as I mentioned, a little while ago, a lot of the way that we learned just in the world, right? Forget about classroom is just going out in the world and figuring out how to get to Brooklyn, right from downtown Manhattan, you're going to have to figure that out, right? You got to figure out the train lines, how they run, run, they run, how much it's going to cost you and maybe you're wrong, and that trial and error learning over time is going to be critical for you to actually learn the right route that you're going to have to take what time of the day you might want to go is it going to be crowded, you know, if it's humid day out, maybe it's better to walk, etc. And that's all stuff that you're just gonna have to learn by experience. So we do this every day, right? We don't sit in a classroom, it's not the only place we learn. And so we're replicating that kind of learning. And some people would say we're evolved to learn best that way, is also going to be really powerful. So if we can actually show in the virtual environments, the consequences of what happens when you make a decision, not just someone telling you, you're right or wrong. But if you're a quarterback, you're making the wrong decision, you see, the ball intercepted, and you feel the deflation in the defeat, of throwing that interception and having other team win. That's a powerful way, having that emotion laden type of feedback is a really powerful teacher. And we know that we want to be able to leverage that as well. So I see us in the technology, you know, heading in that direction as well, because we know that's best for learning. So that's one obvious way we can start to augment even the feedback that we give now. But it's pretty cool to see, like I said, these conversations happening, that would never happen otherwise, that people weren't exposed to that real world environments. I think that feedback alone is even different and better than what happens in current training.

24
00:41:56,460 --> 00:42:27,440
Yeah, as you're talking about this, I just makes me think about how the coaching is going to completely evolve as well, because you have the players that are learning how to do these repetitions and iterations within the technology. But you know, having the coach there be able to observe the player in this virtual environment, but also eventually some point getting eye tracking data and galvanic skin response all these other biometric data markers, you know, that they're going to be able to have all this insight as to what's happening inside internally into the players. And that's never been available to coaches before. And so how is this going to change coaching?

25
00:42:27,600 --> 00:45:29,490
Yeah, I absolutely. So I think in the way that you're alluding to, which is having a better insight into the mind of a learner. And again, if two quarterbacks are making the right decisions, maybe you would think that they're comparable, right? Okay, they knew to throw to the out receiver made their progressions correctly, but maybe they didn't make them in the same amount of time, maybe they didn't use their attention, and the way they should, and then we can get a level deeper, which is what you're saying kind of in the bio physiology, maybe one of them was actually a lot more nervous and a lot more uncertain about where to go, right, we can measure uncertainty nearly right? This is the thing that a lot of researchers do now. And we can see how confident they are and their responses going to get how quick they got there. And that can give you a better indication and at some point, and again, linking that with real world performance data, we can say, okay, unless they pass this threshold in the VR environment, this social being they made the right decision and the right amount of time, efficiently with their gaze and their you know, kind of biometrics look like this. Until they fit that pattern, they're actually not ready. You don't have any of that nuance right now you just have like a yes or no response from them. And then of course, you know, it doesn't always play out like that in the game. And you wonder why. So it's really giving guys access to a level of preparedness that they wouldn't get before. Now, there's another question in terms of like, well, what if they're not prepared? What do you do? I think VR can definitely help right now. But it's not sufficient. I think it's really kind of knowing that they're not prepared with certain plays, then in finding the time and the resources to actually get them better exposure or in a real world use case that we have what's actually happening, what I found is really interesting. So one of our best users in the football realm is a young quarterback, Mitch Stravinsky. And he plays for the Chicago Bears and him and his quarterbacks coach who was also a pretty young guy, Dave McGowan. They love this technology. And Dave loves it because he can actually get an insight into Mitch his decision making that he can't get currently, certainly on the field and especially on the field, in practice, you're only getting certain amount of repetitions, you can't see everything. So it Dave and Mitch are able to do is to go in everybody there every Friday, they're spending an hour hour and a half at Halas Hall, looking at VR, and David's asking Mitch, hey, repeat these plays back to me, what do you see? What do you see? And that seems to be really helping, Mitch in terms of, you know, being confident, but then also helps Dave in terms of like, why know, Mitch is, you know, maybe not comfortable with these plays, maybe some of these plays, and then he can actually progress from there, right? And say, Okay, now when I get to the game, in two days, on Sunday, I know which plays a dial up for much better than I would, if I just saw him practice, right. So it's actually providing Dave more intelligence in terms of his decision making, and how to help coach Mitch in the game. So that's just a wonderful thing to see you again, that layer of insight. And while you know, while we believe we bring a level of expertise to the table with learning and analytics, we're also learning a lot from our users, right? Those who are really invested in the technology. And you're certainly seeing it happen with the younger generations, both in the enterprise training space and in the athletic training space. So it's a cool thing to see. So we're, you know, we're able to both learn from each other. And just what a cool thing to see, like someone actually improving by virtue of the science that we're applying to the technology. So for me, it's it's otherworldly that I'm able to do that. So it's pretty cool.

26
00:45:30,060 --> 00:45:34,500
Didn't the NCAA football champion us driver as well?

27
00:45:34,980 --> 00:46:59,910
Yeah. So the Clemson Tigers were our heaviest users when they won the national championship, not that long ago. And in that, you know, even like I mentioned, Mitch, you know, you saw the progress that he made from year one to year two, pretty amazing as well. So you're seeing a lot of the kind of the best and brightest using this, and then telling us like, this is absolutely a tool that I can't live without. And again, I think we're just scratching the surface. So it's almost like, you know, I'm saying that sounds like as it's really going to work, and they're just they've embraced it, they're using it, they really feel like it's working. But there's even so much more we can do with this technology, we're really just giving them the first layer of like window into that real world environment. But now you start to think about the technological advancements that are being made with things like sick stuff, and a tethered free environment, being able to really freely walk around, at some point, maybe incorporating, you know, other users into that environment meaningfully so that you can interact with him in a more meaningful way, getting kind of the real time feedback, seeing the consequences. So thinking about like having some sort of better intelligence to trigger events based on your decision making, so that the environment itself changes, we're not just stuck with, you know, whatever film that we captured, whatever probably now is certainly useful, you know, you start to see where this technology can go. And you've even seen it. And some of the more cutting edge companies that are doing things into volumetric space, and the haptic feedback space, my analytically and the kind of biometric recording space, I tracking all of that. And that's like, I can't I just can't wait for that world to come. Because I know how much more we're going to get out of this technology when it comes to training.

28
00:47:00,690 --> 00:47:26,610
Well, I think in large part, striver in the work that you're doing a Walmart probably got Facebook and Oculus to actually get their enterprise offerings together after 17,000 goes were sold. And the big press release that there was so many people being trained in VR, clearly, there's a lot of compelling use cases. But that was the goal. And now we have the class that just came out. So what's driver going to be able to do with the quest now?

29
00:47:26,760 --> 00:49:34,800
Yes, like I mentioned, just having this untethered, this was the key. So you know, a lot of what we are dealing with, it's probably with a lot of the world's leading when it comes to adoption. So we're here, you know, talking to other people who are heavily steeped and you know, complete believers in the technology. But these are the people you don't want to convince is everybody else in the world, who kind of, you know, sees, yeah, maybe I can play some games on this and how but it's kind of a pain in the I gotta hook it up to a computer and accept this laptop, we're done with that, right? We've evolved, like even having that standalone untethered, this was a huge step forward for us be able to implement and have that adoption happen. And now they're able to see the value of it, because they're not putting the headsets on and before they were just things that seem pretty trivial, but prohibitive, right, trivial to maybe you and I, well, that's okay, just go plug plug in that said, That's becomes a really pain in the butt for a lot of these guys and figure out ways to kind of build that infrastructure for so many employees, they said became a little bit prohibitive to reach the number of people but now that they created an untethered device, in the go, that was a big step forward for us to access so many more people than we would have otherwise. And again, learn about what's useful and what's not useful from that massive data. And now with the six staff and the class, being able to have them walk around meaningfully, and now you start to think about things like creating a volumetric space where you can actually interact a little bit more meaningfully with the environment where I think it's so incredibly useful for them to have an environment with even just that one point of view, and be able to look around and see what's happening. But now you can actually go over, lean over and see what that that level of presence and engagement that you get from being able to really feel like you have some agency and that environment is huge. Now just for like general engagement and people more motivated to interact with the learning environment. But actually having that learning be more robust, right, you're now starting to elicit more emotional responses, which we know are going to be really good for learning as well. So it's really kind of bringing on this whole host of new experiences for us that we think are going to be much more powerful for learning. And then of course, like I mentioned, we start to bring in things like volumetric capture the environment, being able to kind of swap out objects, you being able to kind of manipulate objects, and some you know, even little bit of a meaningful way of being is going to be really relevant for a lot of the training that's going to happen going forward.

30
00:49:35,700 --> 00:49:59,910
And I just did an interview with worry about from Accenture and Accenture just released a report recently talking about all the big wins of virtual reality, especially in the realm of training. And they have their own way of quantifying that. But that's driver, you have access to all sorts of additional information and analytics. And so how do you tell the story of in what ways is PR training effective? And like how do you quantify that?

31
00:50:00,000 --> 00:52:57,330
Yeah, it's a great question. So that kind of falls squarely within my domain of, you know, when we say VR training work, so what do we mean? And I think you're alluding to this, it's it's highly multi dimensional, right? It's minimally deep, the employees themselves the quarterbacks and do they feel like they're getting a better experience that's really big, right? Even if they were getting it somewhere. So the fact that they think they're getting a better experience is good for just employee engagement. So right off the bat, we have a lot of wins. But of course, we're after something more meaningful, which is actual, real world impact. And for us to be able to, you know, even the other efficiencies that we get from like reducing training time, etc, those are really meaningful to organizations, creating more efficient training, creating more on demand training, so that people can get enough, right. But then we start to look at real learning effects. And we're starting to see, we've already seen a couple instances, obviously can't talk specifically about some of the organizations. But we've been able to do with a couple of big companies, direct comparisons, and ask them, you know, from their traditional training, what do you know, versus the VR training, and we've shown differences for certain concepts being a wired better than they would in the real world. And actually, even kind of more interesting to me, is this dissociation between what people kind of know, versus what people know how to do, right? So there's this like, difference in the kind of cognitive science world of know what versus know how, and what we're really after is know how. So oftentimes, when these people get trained, they're getting the know what right, they're getting the semantic facts, the abstract text based facts, that are really difficult to know if they actually can apply them in the real world, what we're seeing is the know how, and we've actually done some studies that directly compare, hey, this, you know, one person who learned and of course, we do this across hundreds of people, but like, for one person, it's you know, they're learning the know what, so tell us, you know, what should you do in this situation and multiple choice XV format, nailed it, right? Nine out of 10 times you're getting it right? Put them in VR. Now ask them to do that thing without kind of prompting them, you know, and see what they actually do. Like way less than 50% of them know what to do. So you see these used associations, and how much people actually can apply the information. That's really what we're after? Is the application of information, again, that tells us Do you really know what to do? Are you going to be in that real world environment? And are you going to be able to act accordingly? And the answer largely is no, even though the paper and pencil test tells us differently. And I think that's just a huge kind of dissociation for us. So anyway, like I said, we're on a path to kind of always want to know what the real world impact is. So more and more these companies are becoming invested in understanding what's great. These things happen to be are you able to share about our learning? But how is this actually playing out in the real world? And so that's kind of the next step for us is to be able to make that connection to those real world KPIs. That means something for businesses and for quarterbacks. Obviously, it's the same thing for athletes, what's your on the floor performance? And how's that being affected? Which is not trivial, right? Because you want to parcel out the effect of training versus all the other things that affect that number. But we're getting there. And I think we've seen a like I said, a lot of companies that work with us are being really progressive about also wanting to understand that, because that's a direct line to value right, then we know that we can actually invest even more in training that we do now, because we're showing those real world impacts.

32
00:52:58,440 --> 00:53:59,910
Yeah, and I was talking to Eliana from trip and she was talking about how this next iteration of some of these headsets from like my maze, hon, where you have like, dry sensors to be able to get eg data or, you know, these different sensors on the forehead and galvanic skin response, be able to do respiratory breathing, all sorts of new biophysical biometric data, they're going to be able to integrate I tracking data is another huge one. So I imagine that there's various trade offs from like, do you want to use Oculus go to get the scale of Walmart? Do you want to have a spatial like, what dockless class but if you have like, these elite quarterbacks with a PC and like the highest best of the best, then I could imagine like, they're going to want as much information as you can, as long as it's not too hard to get on all these sensors and whatnot, still has to be sort of like a good user experience. But I feel like the next iteration of headsets are going to have that. And so as a neuroscientist, a computational neuroscientist, why are you excited to get your hands on in terms of what type of biophysical and biometric data to start integrated into to get real time feedback in terms of the learning process?

33
00:54:00,000 --> 00:58:04,470
Well, certainly the eye tracking and that's the thing that we know is coming quickly. And obviously a lot of companies who have now since been bought, so companies like SMI, and others who figured out ways to incorporate meaningful eye tracking, and the headsets I think that's a really in you know, Toby and others who are still out there kind of just making the equipment. And we're already kind of seeing product announces from Samsung and others that they're going to have these native in the headset, which is not surprising. That's going to open up not just things for crying, everybody thinks about things like probated rendering. But for us, it's an amazing data point, right? So know, exactly the pattern of gaze, because a lot of the research literature has also gotten us to a point where we know a lot about what gays can tell us about behavior, right? It's kind of the window to the mind kind of thing, right. And so knowing patterns of gaze from the eyes, and not just the head is a lot more meaningful. And I think we're gonna be able to do a lot more in terms of inferring where people's mental states are at, again, things like vigilance and preparedness, engagement, etc, that we can't really get right now we do a pretty good job with the head, and for a lot of things, that is a good proxy for gays. But I'm really excited to see what gays can bring us. And we know, I think it's mostly applies to the social domain. So we have a lot of training that doesn't involve social interactions. But more and more we're seeing our training kind of evolved towards social interactivity. And I think that is key, right. So being able to have a meaningful conversation, if you're in sales, for example, you're doing have some sort of managerial training, we're having to deliver a different conversation to employee or you're a doctor at a children's hospital, you got to tell the parents, you know, it's not going to go so well, how you're able to do that, how comfortable you are with doing that, how effective that social interaction is going to be, it's largely dictated by gaze. And again, this is there's a wealth of research literature into this space that tells us certain gaze patterns can really help us understand what's happening inside somebody's mind. So I'm really excited for that, and that data. And again, you know, just even preparedness, knowing that they're experts and know where to look, I think that's going to be really big. You mentioned durable, we've talked to those guys a lot. I really like those guys Ramses and those guys done something wonderful, which is to be able to build, you know, Eg into a headset. And we know we can do a lot with those eg signals, especially the kind of gross ones that tell us about novelty. And you know, when things are actually eliciting a response that we've see something that's a meaningful object in this environment, we are familiar with it this is something that we're expert with, versus not expert with, is it new, is it new information. And again, those signals in the signal processing algorithms that have come a long way to process that eg information has been really insightful to be able to tell us something meaningful about how people are taking in information. So to people again, kind of going through an experience, if you're just looking at you know how they respond to something that doesn't tell you how comfortable they are with the environment necessarily. I think through those signals, were able to get that extra layer of insight, biophysical signals, like heart rate, heart rate, variability, galvanic skin response, same things, and you mentioned things about usability, and how the ergonomics of that I think that's come a long way, I've tried the neural device, and it's really good, it's really easy to use, it's not very invasive at all. And you know, that obviously, all the signal processing software, they have to go along with it, I've seen it, it's really easy to use, we obviously have yet to test it in our training environment. So that's the moment of truth for us is to see how well it does in predicting behavior in those environments. But, but a lot of faith that that technology will get it because it's so useful. And there's so many really smart people working on that technology. So I'm really looking forward to a lot of that. Now, the question is, well, how do we actually employ it with our folks. And I think it's selectively right, we're always going to have a little bit more progressive individuals who are willing to try and experiment. And that can give us a good head start on understanding when to use that data, because it's not always going to be useful, what context and then how it's going to be used with a bunch of the other data that we can yet again, to make these predictions about behavior. Having access to so many people, we feel like we're in a really good spot to be able to make those assessments and inferences. And it's a matter of finding the right use case for the right customer. And we've already found that to be the case with some of the customers so far, folks who are willing to try and experiment with some of these technologies, because they want to always kind of be on the cutting edge, if it's helping them right, not just for the sake of using the technology, but because it's actually providing something useful and insightful as far as human behavior is concerned.

34
00:58:05,490 --> 00:58:36,300
Well, you mentioned that there's a number of companies that you can't talk about, that you're working with. And you know, obviously you're working with a number of different football teams, NCAA teams that have talked about it. I think that when striker released that press release about how many Oculus goes, were being used by Walmart, you know, in collaboration with that announcement, I think that did a lot to the industry, it made a lot of people wake up in terms of the potential and so and that spirit, is there any other customers that have either announced or disclose that they're working with you?

35
00:58:37,020 --> 01:01:06,060
Yeah, so we have working relationships with a few of the big ones I really am unable to talk about. So I think in due time, they're going to have their own press releases. Fidelity financial is one company that we've that we've made a lot of headway with. And they've gone on the record for us saying that they've actually helped with a lot of their calls center training. So this is kind of the financial services area where there's a lot of transactional things happening with customers, but where they are finding a lot of benefit is in kind of re humanizing that transaction. Right. And so oftentimes, for their customers, they're making not great decisions for themselves. And so they want their employees to be able to have better connection, right, better understanding of who those people are their context in their situations, to be able to help their customers make better decisions for their financial health. And that's something that's obviously really critical in our society now is people being able to have kind of good decision making when it comes to their financial health, and being able to recommend things. So a lot of this is just about, like I said, I think the general term I would use is kind of re humanizing, right? Just putting the kind of human face to that transaction to understand, is this the right thing for that person, instead of just, you know, mindlessly going through the machinations of like, Okay, if then, you know, statements that they're going through with these transactions, maybe they need to take a step back and understand, hey, this person doesn't seem like this is they're in a good situation to be making this kind of withdrawal, or whatever it is, consider their context, ask questions meaningfully, right, that's a critical part of that as well. So you can have a more effective conversation with the customer, so and they feel like they've had a lot better customer interactions. Because of that, they have some data that they've collected to back that up, and we continue to do work with them. So that's one company that has really kind of glommed on to this technology, and we're happy to be working with them in a really progressive group as well. I mean, they're really forward thinking, they have a really cool innovations group that we're able to discuss a lot of these new ideas with, and figuring out how we can incorporate that into their training. So it's been really great to work with those guys, Walmart, obviously, and then even the different areas of Walmart that we've expanded into, you know, we're training basically happens all over the place where we can actually fit in and provide a better training experience. That's been really exciting. And then there's three or four other ones that I'm sure all the time, but really can't talk about. And then there's a host of other right. So, and again, you know, right now we're being pretty conservative, we're able to talk him out. But

36
01:01:06,090 --> 01:01:33,480
yeah, that's why I asked just because I know that the fact that it was the one that Walmart being announced, I think is a big deal. And I look forward to the press releases once they come out, because I think it's important to know how this is getting out there. And I think it's just when Facebook bought Oculus for $2 billion, that was a signal to the rest of the industry. And I feel like with the early evidence that's coming back from Accenture and the feedback that you're getting in terms of the efficacy of this, it feels like it's on the trajectory of like really exploding over the next several years.

37
01:01:33,480 --> 01:02:41,220
Yeah, definitely. And I think once companies see like companies like Walmart actually adopting this, it really gives them pause and into your point, all the other good press, we've gotten and kind of signaling that there's something here in the enterprise space is good for everyone, you know, rising tide, so we're all going to benefit. We welcome everybody kind of engaged and interested in this space. Obviously, Oculus is now on their own with their enterprise platform, which is great. Again, it's signaling that there's a real opportunity here. And we know that just from working with these companies, we can get, you know, again, from the scientific perspective at these best training practices, but also all the other efficiencies that come with the headsets and being able to train through the headset. So there's a host of benefits. Getting back to the question of, you know, how do we measure kind of effectiveness or is VR training working, it's all those ways, and different companies are going to find different benefits for it. But the fact that we're able to provide many benefits, and then kind of the company's experiencing all of them, or even just a subset of them has been really powerful. And you know, if anybody's interested in what companies we've worked with, and what kind of data we've been able to collect and proof points, there's a bunch of case studies that we posted on our website. So feel free to peruse that as well.

38
01:02:42,330 --> 01:02:49,200
So for you, what are some of the either biggest open questions you're trying to answer? or open problems you're trying to solve?

39
01:02:49,380 --> 01:04:59,070
I think technology I mean, that's something that we don't do, right, we don't make the headsets, we don't really kind of work on the technological development, a lot of the not just the headsets, but a lot of the peripheral technologies, content capture content generation, we have some great developers and engineers at our company. You know, we can't expand that team fast enough. So it's cool to see the technology developing. But that's, you know, we're, to some extent beholden to where that technology goes, right. And so it is an and you kind of mentioned this just a second ago, this is kind of like weird, bidirectional feedback. It's like, well, is this the thing? It's like, Okay, great, you know, Strieber found a training case, you know, okay, let's go invest more money into it, but then like, but how much should we invest? And it's like, well, how much? Are they gonna be able to use it? And is it a real training case? So it's like, you know, I think we're kind of slowly helping each other really kind of figure out how to make that technology grow. And the fact that, you know, Oculus has an enterprise platform, you know, obviously, we had something to do with that, to some extent, and signaling that there's a real use case here. And so you're seeing kind of technology developed based on what the market opportunities are, that we're able to uncover, and others are able to uncover. And then of course, but we have to wait for them to really make the big investments, the companies with all that money, all that r&d money, and then the geniuses who kind of created these technologies as well. So I think things like volumetric capture, making more robotic networking people in an environment, so that really feels like you're there, and you're real, and you can have really robust interaction, social interactions, I think all of these things are really going to be critical, how they develop, how we're able to use them, how quickly they can scale, how cheap they are, those are all open questions that we don't totally control. But we're obviously influencing in other ways, by opening up opportunities in those markets. So it's exciting for us to think about where all the possible technological developments can go, meaning the people who are kind of on the bleeding edge of all that stuff, but hoping that this stuff can scale, so that we can actually have that native in the headset, we can develop for it easily, etc. I think those are some just really big open questions. And they're not prohibitive for us right now. But they're things are always kind of keeping on top of and trying to devise strategies around. So that's stimulating, to really kind of think about where the possibilities are, but obviously, where they go is largely going to be determined by what we can show is kind of market value, but also will determine what we can do as a company as far as giving out really meaningful training experiences.

40
01:05:00,300 --> 01:05:08,640
Right? And And finally, what do you think the ultimate potential of immersive technologies are and what they might be able to enable?

41
01:05:08,910 --> 01:07:29,070
So I think you mentioned just from my perspective, and I think we've talked about this before, is just being able to understand people in a way that you can understand them now. So as a behavioral scientists, it's just always fascinating to me to think about being able to get not just the measurements, where we were talking about about measurements and the insights that those can bring. And that's great. I think those technologies will develop independent of VR. But then it's really critical that you measure things in a meaningful context, people behaving in meaningful ways. I think that's where these virtual environments are really impactful on the kind of behavioral research side is, again, you're like I was thinking a dozen years ago, sitting there, man, what if I had the ability to take what I'm doing now, which was this abstract experiment with abstract stimuli and a 2d screen, and put people in a real environment, but one that I can control so I can really understand how they're going to react to different social interactions, how they're going to react to different emotional stressors in their environment, and really get a better understanding of how people work, right. And that's kind of what I've always been after, is really understanding those kind of fundamental things about human behavior, especially learning behavior, so that you can optimize for that, right, you can actually help facilitate learning, we do this in the classroom all the time, we give people the same learning, we just kind of throw it out there to the masses in a classroom of 30 kids all sitting in a desk and assume that they're all supposed to take it in the same way. We know that's not happening, but we don't know what to do about it. Because we don't have the power to really understand what's going on, in their mind moments a moment. But slowly, but surely we are, were able to get that information through these kind of sensors that can capture a lot of meaningful information easily. But then it's not enough just to do that, you also have to have the right environment for them to behave and really understand how it is that they're learning how it is they're taking information and be able to optimize for that. And so I think for just for me, as a behavioral researcher, the more realistic these environments get, the more you can interact like you would in the real world, but also control that environment. Right now we're talking like, all the science fiction movies that we've seen in terms of creating these kind of matrix like environments, not for dystopic reasons, but for really reasons of understanding you know, how people work and be able to kind of understand how they react to different stimuli. For me, just to kind of be able to facilitate and improve and augment learning behaviors. I think that's a pretty cool proposition. So I'm looking forward to that. And of course, we're already seeing that kind of marching forward every year with all these new technological developments. So really excited for that.

42
01:07:30,270 --> 01:07:34,260
Well, is there anything else that's left unsaid that you'd like to say to the immersive community?

43
01:07:34,590 --> 01:08:43,920
Yeah, I mean, obviously, keep building. Like I mentioned, you know, this is kind of a great time we're seeing, I think, the acceleration of the technological curve, of course, with the headsets, and it's really the people who are developing these really amazing one off experiences that are that are setting the kind of North Star right, so you see someone you know, in a basement creating these amazing experiences with this technology, it's not meaningless, right? That it's just a one off experience, because it really should shows you what the world of possible isn't, it kind of sets the mark for the benchmark for where everybody should go. So it's cool to see this community get together and really kind of be able to exchange ideas, because this is the vanguard, right? This is where we're going to see all the new opportunities and new ideas in this space come to life. And then for us to be able to meaningfully take advantage of that provide them at scale, I think that's a, it's an extremely complimentary system, right to have people on the bleeding edge of this stuff really kind of showing us what's possible. And then for people like me to really understand how to make that practical and useful for the world and are in companies like us. And then of course, companies that are doing both, I think is really going to is a cool thing. So I just, you know, keep meeting, keep building and know that like there's other people out there that are watching and looking at this stuff. It's just a kind of a cool time to be in this space. So

44
01:08:45,420 --> 01:08:53,640
awesome. Great. Well, thank you so much for sitting down with me to go into all the details what's happening with driver. And yeah, just thank you for joining me down the podcast. So thank you.

45
01:08:53,720 --> 01:08:59,130
Yeah, always good to talk to you really fun, smart, intelligent, provocative conversation. So appreciate the time.

46
01:08:59,460 --> 01:11:10,500
So that was my Isola. He's the Chief Science Officer at striver. So I'm a number different takeaways about this interview is that first of all, well, I always love catching up with Michael, just because, you know, like I said, at the top of the podcast, he's really on the bleeding edge of working with a whole wide range of different companies. I know that he talks about fidelity, financial, as well as Walmart, and all these other NFL and NC double a football, the Clemson Tigers, lots of different elite sports athletes who are finding a lot of value of being able to do these, essentially, they're capturing like 360 videos, and then to be able to play them back in VR, and to be able to have like a live interactive coaching sessions, but also like working with a whole range of Walmart employees. And to me, it was a bit of a surprise to see the connection between elite quarterback and Walmart employees. But apparently, it's all about like being able to take in all of this unconscious information, whether it's a football player, if you're looking at what the context is, what the down is, where you're out in the field, what's happening with your players with the weather conditions are, you have to like fuse together all these different variables, and to be able to have a certain amount of situational awareness of what the defense is doing, and be able to, to know where to look. And all that is also happening on the level of training people to be managers at Walmart, where you have to be aware of all these different conditions, information that's coming in to be able to make hundreds of different decisions per hour. And to be able to just have this level of situational awareness that's really hard to put into explicit rules to abstract out until like pen and paper tests, it's a lot easier to actually learn on the job. And so what Michael Kasai is saying is that, you know, a lot of what VR is able to do is actually put you into a context and have a lot closer, stimulating you and making you have these social interactions and these emotional intensity of being embedded and having this sense of embodiment in these different contexts. And there's a lot of difference between knowing what and knowing how, so you may know what to do like theoretically abstractly, and taking a multiple choice test, and you're able to answer the right answer. But it's a lot different from actually knowing how which is that you're actually embedded within that context, and you know what to do without having to be prompted, and you just are able to identify the context and be able to make the right decision.

47
01:11:11,970 --> 01:17:59,720
So at the end of this conversation, Michael was saying how there's this kind of dialectic between the pioneers are like pushing the edge of what's possible technologically, there's a lot of research that they're drawing upon to be able to, like, fuse together, but they're operating at scale. So I think in some ways, they have to take a little bit more of a conservative approach, where there may be some of their customers that are willing to do like the duct tape prototype, and to really be on the bleeding edge of integrating all the new technology of, you know, what's coming with like eye tracking data, and EG and all this biometric information so that you're able to get this sense of what's happening with people's comfort and whether or not they're stressed out? And are they looking at the right places, and being able to actually get all this deeper insight into people's levels of cognition with EG and, you know, this is all like on the near future. But immediately, you know, they're working with like, Oculus goes, and, you know, Oculus Rift and HTC Vive. And, you know, at some point, they're gonna start to integrate with dockless quest to be able to have like talis. But, you know, they're operating in such a big scale, but it takes them a little bit longer to integrate some of these different aspects. But at the same time, they're really on the bleeding edge of like integrating something like the Oculus go into enterprise training that was happening at Walmart, like 17,000. Oculus goes, that sent a pretty strong signal to Oculus to get their act together, and to start to actually, like, take the enterprise market seriously. And to spin up their entire enterprise offerings. They made their first announcement here at f8 2018. and expect to have a lot more information about some of their first enterprise offerings and what they're going to be providing to customers at Oculus Connect six, which is coming up in just a couple of weeks here at this point, but just sent a larger signal that there are actually companies that are willing to embrace and take on virtuality, even if it's something is like three degrees of freedom, ocho SCO, which is essentially like a media delivery device, but the way that they're able to like capture 360 video and be able to actually put people into these different contexts and have these different training scenarios. I saw an amazing demo called Avenue asked by Courtney Harding worked in collaboration with Accenture, also just showing the potential and power of using something like ocko, to be able to do these different training scenarios. And she was using a lot more artificial intelligence and working with Kevin Cornish, who has been on the forefront of trying to experiment with AI and how that integrates into the story, and did a really amazing and moving and powerful demo that I saw at SXSW. This year. And you know, Accenture is also just on the bleeding edge of trying to see what's happening in this training space and have an interview with worried above, I'll probably end up eventually, at some point having a whole exploration of what's happening with training within virtual reality, just because I have a number of different conversations and interviews. And that's definitely something that I see is going to be a strong way in which virtuality starting to have like, huge wins and be able to provide some pretty significant value, reducing training time and just making training that's a lot more effective. Sounds like Michael was talking about that they're getting to the point where they're getting a lot more data back from a lot of this first rounds of these different proof of concepts and these prototypes into these different companies, and able to show like specific ways, how VR is able to allow people to understand and grasp specific concepts a lot better than previous methods and able to actually compare and contrast that and sounds like that there's a lot of really positive results from that, and that they're going to be doubling down and expanding a lot of what is already there. And I'm sure also expanding out into lots of other companies as well. I think a theme that came up a number of times throughout this conversation was hearing from Michael, some of his previous frustrations of working in academia, where it was kind of saying boxed out these small use cases, different levels of abstraction. I think with VR, now it's able to like close that gap and able to take something that would have been maybe in an artificial context and studying the behavioral research that now with VR, you can actually get a lot of trying to translate people's actual behavior from what they do in VR, how they behave in real life. And I think that was one of the things that we're trying to look at in terms of like trying to find experts in different domains and put them into a virtual environment, and then to have a whole range of new ways of being able to quantify different things. And being a look at gays and time that they're making these different decisions that there's actually a lot of ways in which the spatial computing technologies are able to quantify certain aspects of behavior that weren't able to be quantified before. And they're able to potentially draw these correlations into like, for example, just talking about I gaze and just to see what you're looking at, and how fast you're able to assess a certain situation. So there's a lot of talk about where your eyes are looking and having that eye tracking data, eventually fused into their training process to be able to assess whether or not you are able to know what to look at. and experts have different ways of the patterns of gays, if you're able to be put into a certain situation with different levels of stressors are high cognitive load, are you still able to make the right decision. And so being able to like, put people into these different contrived situations with VR, but to be able to more closely mimic what the situation might be in the real world. And just that they're able to start to create more of this on demand type of training, and that there seems to be demand for people who want to advance their career to be able to get the training that they need to be able to have some sort of trajectory in these careers. And so just to see how companies like Walmart are starting to, like, lay this out and have these different training programs, the different modules, be able to get this VR training, and then to be able to then not just do a bunch of mental abstractions where you know, you're able to pass the multiple choice test, and then you get put on to the job. And then you still have to do a lot of on the job training, they're just finding that they're able to maybe get that same level of on the job training while doing virtuality training. Now, the thing that I also found interesting was the see how humans are not being completely eliminated from these different situations. But that both in the case of coaches and these elite athletes that the way that coaches are able to have more deeper insight into the decision making process of these quarterbacks, and to be able to have different conversations that they couldn't have before. And just the same within the context of corporate training place like Walmart, being able to put people into an actual context, maybe give them an experience, a direct experience, and then from there and start to then unpack it and have different conversations and start to unpack the decision making process that they went through. And so a little bit more of an interactive process. But something that is a lot more visceral and engaging than just, you know, showing a video or talking about things in the abstract, or actually give them the direct experience, put them in a position where they have to make a decision and then see what they do, and then unpack it from there. So having still humans in the loop, but providing virtuality experiences, to be able to provide a context and a direct experience, that then can be the start of a conversation and an opportunity to actually understand the importance of these deeper high level concepts that they're talking about.

48
01:18:01,620 --> 01:24:22,350
And it sounds like that the trajectory is going to be integrating more and more biophysical factors. For in some situations like at Walmart, they may be just using the Oculus go and then maybe eventually, the Oculus quest. And so they're gonna have to like figure out different levels of volumetric capture, and maybe more CGI creation and going beyond just like 360 videos, but also being able to integrate different aspects of the eye tracking data, the different heart rate variability, and infusing that together with all these different biophysical sensors to be able to figure out, Okay, what are the different factors that are going to determine whether or not someone feels prepared, if they're familiar, if there's a lot of novelty in the scene, lots of different ways in which that you could start to integrate these biophysical markers, and to be able to feed back into the training. And so at some point, making the training even more specified than it is now to be like highly adaptive training, there's this whole concept of spaced repetition. So being able to have space things out, having a lot of variability within different training that you have. And so maybe the biophysical markers can see whether or not your responding to that novelty or not being able to ride that immediate feedback, as well as having enough variation of a concept. Also, just being able to look at the eye tracking and be able to determine whether or not you know, people are comfortable within a conversation sounds like there's just a lot of information that you can get, like almost like the eyes are the window into the mind being able to discern all sorts of different aspects about people's cognitive abilities and their cognitive processing, just by being able to track their eyes and be able to correlate that to what their behavior is. So that's going to be an interesting aspect as well as they move forward. And you know, there's still quite a lot of open questions in terms of the nature of consciousness. And they have a lot of these neuroscience mechanistic ways of describing what's happening in the brain. But there's a certain point where it stops, and I'm talking to Joel Zuckerberg, he was talking about how there's these other aspects of like, the psychological or cognitive aspects of, you know, having these abstract concepts, and how those abstract concepts provide the foundation of the predictive coding model of neuroscience, where you have an expectation of all of your private experience, and that's somehow encapsulated in all these deeper structures of how you understand the world. And Michael was talking about how zero shot learning with an AI is sort of like, you have one instance, and you're able to understand it, and that is extremely, extremely difficult to be able to do, but humans are able to do this kind of so called zero shot learning. But that zero shot learning is also based upon an entire lifetime of lots of different exposures to that data as well, we have these pre existing structures for how we make sense of the reality, even for common sense reasoning and ways that we understand the world all of our mental models. And all of that is that the underlying structure is something that doesn't exist with an AI yet. And so to understand how to have that feedback mechanism with an AI is like the back propagation or the credit assignment problem, which is that if there is an error, and you're trying to correct for it, then how do you distribute the weights in a new way to be able to lead you to the right answer. And I think it's like kind of a mysterious aspect for how our human consciousness and how we come up with these different mental constructs, and how that feedback into like the neural network level. And that's sort of the mystery of being able to like trace down thoughts and be able to unpack a lot of these things, it seems like that linguistics and language and words seemed to be a key part of this of anytime we're able to reduce things down into language into words. And that provides some sort of interface with the rest of the structure of how we make sense and encode information and knowledge within our brains. So language could be a part of you know how those primary category schemas get formed, but still, the interface between how the language and all those concepts are interfacing with how we're perceiving reality is still pretty significant open question, even at the computational neuroscience level, and then how to like feedback that into like the process of learning and how we update these different categories, schemas and have these different errors. And it seems to be that we do have this interface between the pre existing concepts. And anytime we're experiencing something in the world, we're comparing that with all of our prior experience in our concepts, but how that actually plays out at the neural network level is still something that's a bit of a mystery. And that, from Michael's perspective, you know, if that is figured out at some point, then they're going to be able to just really super optimize the process of learning. And so it could be that through the process of working at the scale that they are, and being able to get so much more biometric data and be able to get many different people and just have access to this information to be able to maybe find some of these deeper patterns, maybe they'll be able to find some of these interesting insights into the nature of learning and consciousness and be able to discern different aspects of what's happening from our brain from the EG and be able to contribute back to the wider scientific community in some way. I think that's the challenge is that a company like striver ends up working with a lot of these companies, and then you know, they have access to this huge troughs of data. That's like a goldmine of information, how do you integrate that back into academia, so there's always this pressure of, once you get to that point, as a company, you have your own sort of bottom line of what you need to do to advance as a business. And then there's that obligation to sort of contribute back all this learning back to science, or maybe to collaborate with these different researchers to be able to have, you know, some access to that data, and then to be able to get these deeper insights in the nature of learning the nature of consciousness. So that's just a balance that they have to strike. But you know, from Michael's perspective, he was getting a little tired of not having sort of the concrete ways within academia to be able to have more impact, and be able to directly measure some of these learning behaviors. But with virtual reality, it's sort of this democratization of behavioral science into many different domains. And so you can start to replicate so many different aspects of these different contexts and experiences, and then maybe start to make it more easy to be able to make things that so sort of contrived or abstract within an academic research context, but actually make it feel like it's actually real. And that's what I think is so fascinating about what strivers doing is that they're taking all this insight from the research, but they're actually applying it and seeing what works and what doesn't work. And trying to find the perfect combination of all these things of how to best optimize this process of learning. While they're collaborating with everything from like some of the most elite athletes in the world, to some of the biggest companies in the world who were working at such a huge scale to be able to train all their different employees to be able to do skills that they're just finding like huge impacts for what virtuality can do when it comes to training.

49
01:24:23,600 --> 01:26:12,660
So that's all that I have for today. And I just wanted to thank you for listening to the, which is a VR podcast. And I just wanted to thank you for joining me on this series of this last 13 interviews of doing a deep dive into the neuroscience of the VR. You know, I've been going and traveling to VR conferences last five years, and I've got hundreds of unpublished interviews where I can just kind of dive in into some of these different series. This is a particularly interesting series for me, just because, you know, I went to this future of neuroscience and VR workshop with lots of neuroscientist but it was able to kind of pull together lots of other conversations that I've had over the last three years, conversations that maybe within the context, as I've been publishing things, just sort of, you know, get lost, I will go to a conference, and then I'll publish a number of interviews, and then I'll go to another conference. And so moving to this batch approach of releasing these different conversations, and these themes allows me to kind of go back through the backlog and put together all these conversations and you start to see these different connections and themes amongst all these different conversations over time. And I wouldn't be able to do that or any of this, without the support of you, my listeners, the support of Patreon. And so if you've enjoyed these different types of series, and you want to see more of this, documenting the evolution of spatial computing, and this real time oral history, not only for you right now to understand what's happening, but also for future generations to look back and to learn about the evolution of these spatial computing mediums, then please do consider becoming a supporting member of this Patreon. Just $5 a month is a great amount to give it to give more, that's great. It just allows me to continue to bring you and the rest of the VR community this podcast for free. So become a member and help to sustain and to grow this podcast. So you can become a member and donate today@patreon.com slash with said Dr. Thanks for listening

